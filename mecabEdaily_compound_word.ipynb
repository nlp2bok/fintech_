{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 복합명사 추출을 위한 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "test_word = []\n",
    "compound_noun = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스기사에서 명사만 추출하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    if i >= 9:\n",
    "        news = pd.read_csv('data/edaily/edaily{}_news.csv'.format(i+1))\n",
    "\n",
    "    else:\n",
    "        news = pd.read_csv('data/edaily/edaily0{}_news.csv'.format(i+1))\n",
    "\n",
    "    for news_content in news['content']:\n",
    "        try:\n",
    "            for word, pos in mecab.pos(news_content):\n",
    "                if (re.search('NNP|NNG', pos)):\n",
    "                    pos_words.append(word)\n",
    "        except:\n",
    "            print(\"news_content 에러\")\n",
    "            \n",
    "print(\"pos_words의 길이 : \", len(pos_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추출된 명사를 복합명사로 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pos_words) - 1):\n",
    "\n",
    "    try:\n",
    "        words_4 = pos_words[i] + pos_words[i+1] + pos_words[i+2] + pos_words[i+3]\n",
    "        if not words_4 in test_word:\n",
    "            test_word.append(words_4)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        words_3 = pos_words[i] + pos_words[i+1] + pos_words[i+2]\n",
    "        if not words_3 in test_word:\n",
    "            test_word.append(words_3)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    words_2 = pos_words[i] + pos_words[i+1]\n",
    "    if not words_2 in test_word:\n",
    "        test_word.append(words_2)\n",
    "\n",
    "    print(\"test_word의 길이 : \", len(test_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조합한 복합명사와 실제 뉴스기사의 복합명사를 비교하여 \n",
    "### 일치하면 최종 복합명사리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(12):\n",
    "    \n",
    "    if j >= 9:\n",
    "        news = pd.read_csv('data/edaily/edaily{}_news.csv'.format(j+1))\n",
    "\n",
    "    else:\n",
    "        news = pd.read_csv('data/edaily/edaily0{}_news.csv'.format(j+1))\n",
    "        \n",
    "    \n",
    "    try :\n",
    "        for news_content in news['content']:\n",
    "\n",
    "            for content_sentence in news_content.split('.'): \n",
    "\n",
    "                for content_word in content_sentence.split(' '):\n",
    "\n",
    "                    if ((content_word) or (content_word[0:-1]) or (content_word[0:-2])) in test_word:\n",
    "                        if not test_word in compound_noun:\n",
    "                            compound_noun.append(test_word)\n",
    "                                                 \n",
    "    except Exception as ex:\n",
    "        print(\"에러 : \", ex)\n",
    "        \n",
    "                        \n",
    "    print(\"compound_noun의 길이 : \", len(compound_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/pos_words.txt', 'a', encoding=\"utf8\")\n",
    "\n",
    "for word in pos_words:\n",
    "    file.write(str(word)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/test_word.txt', 'a', encoding=\"utf8\")\n",
    "\n",
    "for word in test_word:\n",
    "    file.write(str(word)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/compound_word.txt', 'a', encoding=\"utf8\")\n",
    "\n",
    "for word in compound_noun:\n",
    "    file.write(str(word)+'\\n')\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
