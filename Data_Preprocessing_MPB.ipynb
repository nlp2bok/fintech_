{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing_MPB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlp2bok/fintech_/blob/lmh_dev/Data_Preprocessing_MPB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8krwcoAYBEJd",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl0c3I6vBEJe",
        "colab_type": "text"
      },
      "source": [
        "##. 1. 금통위 의사록(MPB Analysis Report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N63xEVpaBEJf",
        "colab_type": "text"
      },
      "source": [
        "1. MPB 데이터 병합\n",
        "\n",
        " 160개의 금통위 의사록을 하나의 csv파일에 넣는다.\n",
        "  파일명에서 rDate추출, 파일 read를 통한 내용 추출('작성일자','내용')\n",
        "2. 다양한 Tokenized 방식을 통해 전처리를 실행한다.\n",
        "\n",
        " Komoran, Hannanum,  Okt, Kkma, Mecab => Mecab사용\n",
        " \n",
        " -> Mecab install 필요\n",
        "3. Token에 한글 태그를 부착한다.\n",
        "4. 불용어 처리를 실행한다.\n",
        "5. csv파일에 preprocessing data 컬럼을 추가한다(preData)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIygVG5BEJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwixaBr1BEJj",
        "colab_type": "text"
      },
      "source": [
        "##Step 1. 전체 파일을 하나의 파일로 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQMaqrEgBEJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(dirpath) #현재경로 출력\n",
        "workDIr = os.path.abspath('/Users/minhyeon/Desktop/Data_Preprocessing_MPB/MPB_Contents/')\n",
        "cnt = 0\n",
        "\n",
        "def fileopen(path):\n",
        "    f = open(path,'r', encoding='utf-8')\n",
        "    line = f.read()\n",
        "    f.close()\n",
        "    \n",
        "    return line \n",
        "\n",
        "with open('MPB_File.csv', 'w', encoding='utf-8', newline='') as cvsFile :\n",
        "    wr = csv.writer(cvsFile)\n",
        "\n",
        "    for dirpath, dirnames, filenames in os.walk(workDIr):\n",
        "        for filename in filenames:\n",
        "            #파일 컨텐츠 읽기\n",
        "            path = dirpath+'/'+filename\n",
        "            fType = filename[-4:]\n",
        "            try:\n",
        "                if fType == \".txt\" : \n",
        "                    text = fileopen(path)\n",
        "                else :\n",
        "                    continue\n",
        "                #파일 타입 체크\n",
        "            except Exception as ex:\n",
        "                print(filename + '파일 read 에러가발생 했습니다', ex)\n",
        "\n",
        "\n",
        "            try:\n",
        "                rDate = filename[:4] #Report Date, String형\n",
        "                #print(cnt)\n",
        "                cnt += 1\n",
        "                wr.writerow([rDate,text])\n",
        "            except Exception as ex:\n",
        "                print(filename + '에러가 발생 했습니다', ex)\n",
        "    \n",
        "cvsFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyyZwD6jBEJm",
        "colab_type": "text"
      },
      "source": [
        "## Step2. Tokenized 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBTGz34ABEJm",
        "colab_type": "text"
      },
      "source": [
        "##2-1. 파일 읽어오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n5PMpBsBEJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#csv파일을 읽어오고 column명을 설정해준다.\n",
        "mydata = pd.read_csv(\"MPB_File.csv\",names=['rDate','MPBcontent'],encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HLmQyqkBEJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#읽어온 데이터를 DataFrame형식으로 담는다.\n",
        "df = pd.DataFrame(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgOLrF4uBEJr",
        "colab_type": "code",
        "colab": {},
        "outputId": "9fd19dfc-4011-4ddb-8722-e8795e0bc3ac"
      },
      "source": [
        "#mycontent에 전처리할 데이터만 담는다.\n",
        "mycontent = df['MPBcontent']\n",
        "print(len(mycontent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVnfS1ebBEJv",
        "colab_type": "text"
      },
      "source": [
        "## 2-2. 다양한 방식의 Tokenized 활용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp1LvrH0BEJw",
        "colab_type": "text"
      },
      "source": [
        "기사별 Tokenized한 값을 komoran_tokens, hannanum_tokens, okt_tokens, kkma_tokens, Mecab_tokens로 각각 저장한 후 결과를 확인해본다.\n",
        "\n",
        "-> 채권보고서에서 Mecab성능이 가장 좋은 것을 확인하였음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO4X7Kp8BEJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MeCab 토큰화\n",
        "from ekonlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "mecab_tokens = []\n",
        "for i in range(len(mycontent)):\n",
        "    try:\n",
        "        #print(mecab.pos(mycontent[i]))\n",
        "        #break\n",
        "        mecab_tokens.append(mecab.morphs(mycontent[i]))\n",
        "        #print(i)\n",
        "    except:\n",
        "        #이상 데이터 제외\n",
        "        print(str(i)+\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQerbYolBEJy",
        "colab_type": "text"
      },
      "source": [
        "##Step3. Mecab을 사용하여 한글 태그 부착\n",
        "가장 성능이 좋은 Mecab을 활용하기로 하였음.\n",
        "\n",
        "한글 태그 부착은 .pos를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbmOA8oFBEJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MeCab 토큰화(ekonlpy를 통한 한글 태그 부착 -> ekonlpy 설치 필요)\n",
        "from ekonlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "mecab_tokens = []\n",
        "for i in range(len(mycontent)):\n",
        "    try:\n",
        "        mecab_tokens.append(mecab.pos(mycontent[i]))\n",
        "        #print(i)\n",
        "    except:\n",
        "        #이상 데이터 제외\n",
        "        print(str(i)+'error')\n",
        "        #이상한 데이터에는 빈 값을 넣어준다.\n",
        "        mecab_tokens.append(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFLjCYjFBEJ0",
        "colab_type": "code",
        "colab": {},
        "outputId": "5ff087e9-7359-4e97-f166-7322af9d96a8"
      },
      "source": [
        "#한글태그 부착확인\n",
        "print(mecab_tokens[0][1])\n",
        "print(mecab_tokens[0])\n",
        "\n",
        "#데이터 개수 확인\n",
        "print(len(mycontent))\n",
        "print(len(mecab_tokens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('년', 'NNBC')\n",
            "160\n",
            "160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5phbvssBEJ3",
        "colab_type": "text"
      },
      "source": [
        "##Step4. 불용어 처리\n",
        "\n",
        "(1) stopInclude에 포함된 품사만 남긴다.\n",
        "\n",
        "(2) stopWord는 불필요한 단어를 수동으로 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGnfgbVVBEJ3",
        "colab_type": "text"
      },
      "source": [
        "mecab-ko-dic 품사태그\n",
        "\n",
        "명사(NNG), 형용사(VA,VAX), 부사(MAG), 동사(VA)만 추출\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7IclsYCBEJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##명사(NNG), 형용사(VA,VAX), 부사(MAG), 동사(VA)\n",
        "includePos = ['NNG','VA','VAX','MAG','VA']\n",
        "stopWord = [\"덤프데이터\"]\n",
        "result =[]\n",
        "preresult = []\n",
        "cnt = 0\n",
        "#1493개의 mecab_tokens loop\n",
        "for mecab_token in mecab_tokens :\n",
        "    #print(mecab_token)\n",
        "    #mecab_token(i)번째의 (word/형태소) 데이터에 접근 => wordData = ('단어','품사')\n",
        "    cnt+=1\n",
        "    #print(cnt)\n",
        "    for wordData in mecab_token:\n",
        "        #('단어','품사')중 '형태소' 데이터가 stopInclude에 포함, '단어' 데이터가 stopWord에 포함되지 않으면 저장한다.\n",
        "        try:\n",
        "            if wordData[1] in includePos:\n",
        "                if wordData[0] not in stopWord:\n",
        "                    preresult.append(wordData[0])\n",
        "        except:\n",
        "            continue\n",
        "    result.append(','.join(preresult))\n",
        "    preresult = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhQkrecZBEJ6",
        "colab_type": "text"
      },
      "source": [
        "##Step5. 전처리된 데이터를 기존 파일에 추가한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmMfKS6xBEJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(len(result))\n",
        "df['preData'] = result\n",
        "print(df['preData'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gb60jnUBEJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df.to_csv(\"/Users/minhyeon/Desktop/Data_Preprocessing_MPB/MPB_final.csv\", header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcOFJiyBEJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = pd.read_csv(\"MPB_final.csv\",encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4_QC7uBBEKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(text['preData'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}